{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oroz/anaconda3/envs/gaussian_splatting/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/oroz/anaconda3/envs/gaussian_splatting/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODER: F\n",
      "train self.face_ids ['017', '018', '024', '030', '031', '032', '033', '035', '036', '037', '038', '040', '042', '043', '055', '056', '057', '058', '060', '061', '063', '064', '065', '067', '068', '068', '069', '071', '072', '073', '074', '075', '076', '077', '078', '079', '080', '081', '082', '083', '085', '088', '089', '090', '091', '092', '093', '094', '095', '096', '097', '098', '099', '100', '102', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '162', '163', '164', '165', '166', '167', '168', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '191', '192', '193', '194', '195', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '214', '215', '216', '217', '218', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '266', '267', '269', '270', '271', '272', '274', '275', '276', '277', '278', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '293', '294', '295', '297', '298', '299', '301', '302', '303', '304', '305', '306', '307', '308', '309', '310', '311', '312', '313', '314', '315', '316', '317', '318', '319', '320', '321', '322', '323', '324', '325', '326', '327', '328', '329', '330', '331', '332', '333']\n",
      "ENCODER: F\n",
      "val self.face_ids ['059', '070', '368', '369', '370', '371', '372', '373', '374', '375']\n",
      "id: 375/EXP-1-head\n",
      "using presonalized flame\n",
      "no. of gaussians: 81418\n"
     ]
    }
   ],
   "source": [
    "from data_processing.dataset import FaceDataset\n",
    "import pytorch_lightning as L\n",
    "from model.gauss_predictor import GaussPredictor\n",
    "from model.gauss_predictor_with_latent_codes import GaussPredictorWithLatentCodes\n",
    "from data_processing.data_module import FaceDataModule\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.callbacks.model_checkpoint import ModelCheckpoint\n",
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "\n",
    "config = yaml.safe_load(open('configs/settings_final_template_flame.yaml', 'r'))\n",
    "config['data']['force_rebuild'] = True\n",
    "config['data']['save_results'] = False\n",
    "\n",
    "face_data_module = FaceDataModule(config=config)\n",
    "face_data_module.setup('fit')\n",
    "\n",
    "#gauss_predictor = GaussPredictor.load_from_checkpoint(config['model']['checkpoint'], config=config, data_module=face_data_module)\n",
    "#gauss_predictor.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    batch = face_data_module.val_dataloader().dataset[9]\n",
    "\n",
    "    initial_gaussians = batch['initial_gaussians']\n",
    "    images = batch['images']\n",
    "    target_depths = batch['depths']\n",
    "    sequence_id = batch['sequence_id']\n",
    "\n",
    "    camera_params = batch['camera_params']\n",
    "    camera_params['cam_2_world_poses'] = FaceDataset.dicts_to_poses(camera_params['cam_2_world_poses'])\n",
    "\n",
    "    input_serials = batch['input_serials']\n",
    "    input_cam_2_world_poses = {serial: cam_2_world_pose for serial, cam_2_world_pose in camera_params['cam_2_world_poses'].items() if serial in input_serials}\n",
    "    input_camera_params = {'cam_2_world_poses': input_cam_2_world_poses, 'intrinsics': camera_params['intrinsics']}\n",
    "\n",
    "    #predicted_gaussians = gauss_predictor.forward({key: val.to(gauss_predictor.device) for key, val in initial_gaussians.items()})\n",
    "\n",
    "    gaussian_xyz_start = initial_gaussians['xyz'].cuda()\n",
    "    #gaussian_xyz_pred = predicted_gaussians['xyz'].cuda()\n",
    "    #gaussian_scales = predicted_gaussians['scaling'].cuda()\n",
    "    #opacities = predicted_gaussians['opacity'].cuda()\n",
    "    features = initial_gaussians['features'].cuda()\n",
    "\n",
    "    #dists = (gaussian_xyz_pred - gaussian_xyz_start).square().sum(-1).sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dists.min())\n",
    "#print(dists.max())\n",
    "\n",
    "#log_dists = dists.log1p()\n",
    "#dists_np = dists.cpu().numpy()\n",
    "#dists_np = np.log(dists_np)\n",
    "# dists = (dists - dists.min()) / (dists.max() - dists.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb212f97dba4ebfaeb7174110046d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import k3d\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "plot = k3d.plot(grid_auto_fit=False, grid_visible=False, height=1024)\n",
    "\n",
    "#dists_np = features.cpu().numpy()[:, -3]\n",
    "#dists_np = gaussian_scales.exp().cpu().numpy().sum(-1)\n",
    "#dists_np = opacities.cpu().numpy().sum(-1)\n",
    "\n",
    "#plot += k3d.points(gaussian_xyz_pred.cpu().numpy(), point_size=0.005, color_map=k3d.colormaps.matplotlib_color_maps.Viridis, attribute=dists_np, color_range=[0, 1])\n",
    "plot += k3d.points(gaussian_xyz_start.cpu(), point_size=0.005, colors=[0x888888]*gaussian_xyz_start.shape[0])\n",
    "\n",
    "plot.display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaussian_splatting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
