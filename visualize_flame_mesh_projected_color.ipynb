{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oroz/anaconda3/envs/gaussian_splatting/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/oroz/anaconda3/envs/gaussian_splatting/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from data_processing.dataset import FaceDataset\n",
    "from flame.flame_model_creation import FlameModelCreation\n",
    "from pytorch3d.io import load_obj\n",
    "import numpy as np\n",
    "import pytorch3d.structures\n",
    "import torch\n",
    "import flame.flame as imfp\n",
    "import flame.lbs as lbs\n",
    "from dreifus.matrix import Pose, Intrinsics\n",
    "import trimesh\n",
    "import pytorch3d\n",
    "from pytorch3d.ops import sample_points_from_meshes\n",
    "import numpy as np\n",
    "import k3d\n",
    "import matplotlib.cm as cm\n",
    "from gaussian_splatting.utils.sh_utils import SH2RGB\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def create_flame_model(tracked_flame_params_path, config):\n",
    "    flame_model = imfp.FlameHead(shape_params=300, expr_params=100)\n",
    "    flame_data = np.load(tracked_flame_params_path)\n",
    "    \n",
    "    shape_params = torch.tensor(np.tile(flame_data['shape'], (128, 1)))\n",
    "    expression_params = torch.tensor(flame_data['expression'])\n",
    "    pose_params=torch.tensor(FlameModelCreation._create_pose_param(flame_data['jaw']))\n",
    "    neck_pose = torch.tensor(flame_data['neck'])\n",
    "    eye_pose = torch.tensor(flame_data['eyes'])\n",
    "    jaw = torch.tensor(flame_data['jaw'])\n",
    "    \n",
    "    # FLAME MODEL\n",
    "    i=0 #timestep\n",
    "    flame_vertices, flame_lms = flame_model.forward3(\n",
    "        shape=shape_params[[i]],  # We always assume the same shape params for all timesteps\n",
    "        expr=expression_params[[i]],\n",
    "        rotation=None,#rotation[[i]],\n",
    "        neck=neck_pose[[i]], \n",
    "        jaw=jaw[[i]],           \n",
    "        eyes= eye_pose[[i]],\n",
    "        translation=None,\n",
    "        pose_params=pose_params[[i]]\n",
    "    )\n",
    "    \n",
    "    # model transformation\n",
    "    flame_faces = flame_model.faces\n",
    "    #flame_vertices, flame_faces = upsample_flame(flame_vertices, flame_model.faces, config)\n",
    "    flame_vertices = flame_vertices.squeeze()\n",
    "    flame_faces = flame_faces.squeeze()\n",
    "\n",
    "    flame_face_midpoints =  flame_vertices[flame_faces].mean(dim=1)\n",
    "    return flame_vertices.cpu().numpy(), flame_faces.cpu().numpy(), flame_face_midpoints.cpu().numpy()\n",
    "\n",
    "def upsample_flame(flame_vertices, flame_faces, config):\n",
    "    if not config['data']['upsample_flame_iterations']:\n",
    "        return flame_vertices\n",
    "    upsample_flame_iterations = config['data']['upsample_flame_iterations']\n",
    "    if len(flame_faces.shape) == 2:\n",
    "        flame_faces = flame_faces.unsqueeze(0)\n",
    "    p3d_mesh = pytorch3d.structures.Meshes(flame_vertices, flame_faces)\n",
    "    p3d_mesh_subdivision = pytorch3d.ops.SubdivideMeshes()\n",
    "    \n",
    "    for _ in range(upsample_flame_iterations):\n",
    "        p3d_mesh = p3d_mesh_subdivision(p3d_mesh)\n",
    "        \n",
    "    vertices = p3d_mesh.verts_list()[0]\n",
    "    faces = p3d_mesh.faces_list()[0]\n",
    "    return vertices.unsqueeze(0), faces.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODER: F\n",
      "val self.face_ids ['059', '070', '368', '369', '370', '371', '372', '373', '374', '375']\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'flame_faces' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m camera_params \u001b[38;5;241m=\u001b[39m val_dataset\u001b[38;5;241m.\u001b[39mget_camera_params(sequence)\n\u001b[1;32m     20\u001b[0m images \u001b[38;5;241m=\u001b[39m val_dataset\u001b[38;5;241m.\u001b[39mget_images(sequence, camera_params)\n\u001b[0;32m---> 22\u001b[0m flame_vertices, flame_faces, flame_midpoints \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_flame_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mflame_params_path\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m val_dataset\u001b[38;5;241m.\u001b[39mscale_and_rotate(flame_vertices, camera_params, sequence)\n\u001b[1;32m     27\u001b[0m input_images \u001b[38;5;241m=\u001b[39m {serial: image \u001b[38;5;28;01mfor\u001b[39;00m serial, image \u001b[38;5;129;01min\u001b[39;00m images\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m serial \u001b[38;5;129;01min\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_serials\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n",
      "Cell \u001b[0;32mIn[1], line 48\u001b[0m, in \u001b[0;36mcreate_flame_model\u001b[0;34m(tracked_flame_params_path, config)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# model transformation\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m#flame_vertices, flame_faces = upsample_flame(flame_vertices, flame_model.faces, config)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m flame_vertices \u001b[38;5;241m=\u001b[39m flame_vertices\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m---> 48\u001b[0m flame_faces \u001b[38;5;241m=\u001b[39m \u001b[43mflame_faces\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     50\u001b[0m flame_face_midpoints \u001b[38;5;241m=\u001b[39m  flame_vertices[flame_faces]\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m flame_vertices\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), flame_faces\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), flame_face_midpoints\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'flame_faces' referenced before assignment"
     ]
    }
   ],
   "source": [
    "config = yaml.safe_load(open('configs/settings_final.yaml', 'r'))\n",
    "val_dataset = FaceDataset(config, data_split='val')\n",
    "idx = 1\n",
    "\n",
    "def load_obj_vertices(filename):\n",
    "    vertices = []\n",
    "    \n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('v '):  # Lines that define vertices start with 'v'\n",
    "                parts = line.split()\n",
    "                vertices.append([float(parts[1]), float(parts[2]), float(parts[3])])\n",
    "    \n",
    "    return np.array(vertices)\n",
    "\n",
    "sequence = val_dataset.sequences[idx]\n",
    "\n",
    "camera_params = val_dataset.get_camera_params(sequence)\n",
    "\n",
    "images = val_dataset.get_images(sequence, camera_params)\n",
    "\n",
    "flame_vertices, flame_faces, flame_midpoints = create_flame_model(sequence['flame_params_path'], config)\n",
    "\n",
    "val_dataset.scale_and_rotate(flame_vertices, camera_params, sequence)\n",
    "\n",
    "\n",
    "input_images = {serial: image for serial, image in images.items() if serial in config['data']['input_serials']}\n",
    "\n",
    "gaussian_colors = val_dataset.get_projected_colors(sequence, camera_params, flame_vertices, input_images, max_dist_factor=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa77a783e16c48cbaee267f4d96306a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = SH2RGB(gaussian_colors)\n",
    "color_list = (colors*255).tolist()\n",
    "color_map = [((int(r) << 16) | (int(g) << 8) | int(b)) for r, g, b in color_list]\n",
    "\n",
    "# Initialize plot\n",
    "plot = k3d.plot(grid_visible=False, height=1024)\n",
    "\n",
    "# Create a mesh with colored faces\n",
    "#plot += k3d.mesh(flame_vertices, flame_faces, colors=[0x888888]*flame_vertices.shape[0])\n",
    "plot += k3d.points(flame_vertices, point_size=0.005, colors=[0x888888]*flame_vertices.shape[0])\n",
    "#plot += k3d.points(flame_vertices, point_size=0.005, colors=color_map)\n",
    "\n",
    "# Add the mesh to the plot\n",
    "#plot += mesh\n",
    "\n",
    "# Display the plot\n",
    "plot.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# def save_obj(vertices, faces, filename):\n",
    "#     with open(filename, 'w') as f:\n",
    "#         # Write vertices\n",
    "#         for vertex in vertices:\n",
    "#             f.write(f'v {vertex[0]} {vertex[1]} {vertex[2]}\\n')\n",
    "        \n",
    "#         # Write faces\n",
    "#         for face in faces:\n",
    "#             # OBJ format uses 1-based indexing\n",
    "#             f.write(f'f {face[0] + 1} {face[1] + 1} {face[2] + 1}\\n')\n",
    "            \n",
    "# # Save to OBJ file\n",
    "# save_obj(flame_vertices, flame_faces, 'output.obj')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaussian_splatting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
